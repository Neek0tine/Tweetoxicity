{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from text import cleaning, flat\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Models & Vectorizer (Text --> matrix of TF-IDF features.)\n",
    "def load_model():\n",
    "    with open('./pickle/CombineModel.pkl', 'rb') as filemodel:\n",
    "        model = pickle.load(filemodel)\n",
    "        \n",
    "    with open('./pickle/vectorizer.pkl', 'rb') as filevectorizer:\n",
    "        vectorizer = pickle.load(filevectorizer)\n",
    "        \n",
    "    return model, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String to matrix of TF-IDF features.\n",
    "def vectorize(vectorizer, text):\n",
    "    cleantext = cleaning(text)\n",
    "    print(f\"Before Cleaning: {text}\")\n",
    "    print(f\"After Cleaning: {cleantext}\")\n",
    "    \n",
    "    vect = vectorizer.transform([cleantext])\n",
    "    \n",
    "    return vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using three models (NB, SVM, Logistic Regs)\n",
    "def predict(model, vect):\n",
    "    LRpred = model['LRmodel'].predict(vect)\n",
    "    SVCpred = model['SVCmodel'].predict(vect)\n",
    "    BNBpred = model['BNBmodel'].predict(vect)\n",
    "        \n",
    "    LRpred_conf = max(flat(model['LRmodel'].predict_proba(vect)))\n",
    "    SVCpred_conf = max(flat(model['SVCmodel'].predict_proba(vect)))\n",
    "    BNBpred_conf = max(flat(model['BNBmodel'].predict_proba(vect)))\n",
    "        \n",
    "    result = np.concatenate((LRpred, SVCpred, BNBpred))\n",
    "    result_conf = [LRpred_conf, SVCpred_conf, BNBpred_conf]\n",
    "        \n",
    "    result = pd.DataFrame({\n",
    "        'model': ['Logistic Reg', 'SVM', 'NB'],\n",
    "        'predict': result,\n",
    "        'confidence': result_conf\n",
    "        })\n",
    "    print(f\"3 Models Prediction:\\n{result}\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority Algorithm (Voting System)\n",
    "def majority_algoritm(result):\n",
    "    result_pred = result.predict.mode()[0]\n",
    "    confidence = round(result[result['predict'] == result.predict.mode()[0]]['confidence'].mean()*100,2)\n",
    "    print(f\"Final Predict: {result_pred}\")\n",
    "    print(f\"Confidence Mean: {confidence}%\")\n",
    "    \n",
    "    return result_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Sentiment Stats\n",
    "def sentiment_stats(sentiment):\n",
    "    df = pd.DataFrame({\n",
    "        'sentiment':sentiment\n",
    "    })\n",
    "    test = df['sentiment'].value_counts().to_frame()\n",
    "    test['percentage'] = round(test['sentiment'] / test['sentiment'].sum() * 100,2)\n",
    "    # plot = plt.pie(test)\n",
    "    print(f\"SENTIMENT STATS:\\n{test}\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Cleaning: Given the almost unimaginable nature of the present, what will the future be? https://t.co/b2Yw0AXGVA @elonmusk\n",
      "After Cleaning: given almost unimaginable nature present future\n",
      "3 Models Prediction:\n",
      "          model   predict  confidence\n",
      "0  Logistic Reg  POSITIVE    0.797019\n",
      "1           SVM  POSITIVE    0.724450\n",
      "2            NB  POSITIVE    0.773338\n",
      "Final Predict: POSITIVE\n",
      "Confidence Mean: 76.49%\n",
      "==========================\n",
      "\n",
      "Before Cleaning: Unless susceptible to extreme natural disasters, nuclear power plants should not be shut down\n",
      "After Cleaning: unless susceptible extreme natural disaster nuclear power plant shut\n",
      "3 Models Prediction:\n",
      "          model   predict  confidence\n",
      "0  Logistic Reg  NEGATIVE    0.534753\n",
      "1           SVM  POSITIVE    0.509576\n",
      "2            NB  NEGATIVE    0.608619\n",
      "Final Predict: NEGATIVE\n",
      "Confidence Mean: 57.17%\n",
      "==========================\n",
      "\n",
      "Before Cleaning: Nothing is more permanent than a â€œtemporaryâ€ government program\n",
      "After Cleaning: nothing permanent temporary government program\n",
      "3 Models Prediction:\n",
      "          model   predict  confidence\n",
      "0  Logistic Reg  NEGATIVE    0.651430\n",
      "1           SVM  NEGATIVE    0.591467\n",
      "2            NB  NEGATIVE    0.665014\n",
      "Final Predict: NEGATIVE\n",
      "Confidence Mean: 63.6%\n",
      "==========================\n",
      "\n",
      "SENTIMENT STATS:\n",
      "          sentiment  percentage\n",
      "NEGATIVE          2       66.67\n",
      "POSITIVE          1       33.33\n"
     ]
    }
   ],
   "source": [
    "def inisiasi(input_text):\n",
    "    # load vectorizer and model pickle\n",
    "    model, vectorizer = load_model()\n",
    "\n",
    "    sentiment = []\n",
    "\n",
    "    for text in input_text:\n",
    "        # initiate vectorizer function\n",
    "        vect = vectorize(vectorizer, text)\n",
    "        \n",
    "        # initiate predict function\n",
    "        result = predict(model, vect)\n",
    "        \n",
    "        # initiate majority algorithm function\n",
    "        score = majority_algoritm(result)\n",
    "        sentiment.append(score)\n",
    "        print(\"==========================\\n\")\n",
    "\n",
    "    overall_sentiment = sentiment_stats(sentiment)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_input = [\"Given the almost unimaginable nature of the present, what will the future be? https://t.co/b2Yw0AXGVA @elonmusk\", \n",
    "                  \"Unless susceptible to extreme natural disasters, nuclear power plants should not be shut down\",\n",
    "                  'Nothing is more permanent than a â€œtemporaryâ€ government program']\n",
    "    inisiasi(test_input)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9614373613a18e3522af50f71d4d8a6930b31566ad7ad82e9aaf0473e52b5d3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('myenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
